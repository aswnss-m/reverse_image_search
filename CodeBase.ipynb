{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector Creator Using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary libraries\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model without the classification layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(img_path):\n",
    "    # Load image from file path and resize to 400x400\n",
    "    print(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    # Convert image to numpy array and expand dimensions to match input shape of VGG16\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    # Preprocess input image using the same method as used during training VGG16\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Pass the preprocessed image through the VGG16 model and obtain the feature vector\n",
    "    features = base_model.predict(x)\n",
    "    \n",
    "    # Flatten the feature vector and return as 1D array\n",
    "    feature_vector = features.flatten()\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_photos(photo_subset):\n",
    "    # Process each photo in the subset\n",
    "    subset_feature_vectors = []\n",
    "    for photo_path in tqdm_notebook(photo_subset, desc='Processing subset'):\n",
    "        # Process the photo and extract the feature vector\n",
    "        feature_vector = get_feature_vector(photo_path)\n",
    "        print(\"done one\")\n",
    "        subset_feature_vectors.append(feature_vector)\n",
    "    \n",
    "    return subset_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where the logos are stored\n",
    "logo_dir = './LLD-logo_files/LLD-logo-files/'\n",
    "\n",
    "# Initialize empty lists to store the feature vectors and labels\n",
    "feature_vectors = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through all the image files in the logos directory\n",
    "with open(\"./LLD-logo_files/subsets/subset_files_12.txt\") as f:\n",
    "    filenames = f.read().split(\"\\n\")\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    # Check if the file is a PNG image\n",
    "    if filename.endswith('.png'):\n",
    "        # Construct the full file path\n",
    "        img_path = os.path.join(logo_dir, filename)\n",
    "        # Obtain the feature vector for the image and append it to the feature_vectors list\n",
    "        feature_vector = get_feature_vector(img_path)\n",
    "        \n",
    "        if len(feature_vector) > 0:\n",
    "            feature_vectors.append(feature_vector)\n",
    "            # Extract the label from the filename and append it to the labels list\n",
    "            label = filename.split('.')[0]  # Assuming the label is the part of the filename before the extension\n",
    "            labels.append(label)\n",
    "\n",
    "# Convert the feature_vectors and labels lists to numpy arrays\n",
    "feature_vectors = np.array(feature_vectors)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Round the feature vectors to a specified number of decimal places (e.g., 6)\n",
    "feature_vectors = np.round(feature_vectors, decimals=6)\n",
    "\n",
    "# Save the feature_vectors array as a numpy file\n",
    "np.save('feature_vectors_12.npy', feature_vectors)\n",
    "\n",
    "dataframe_vectors = [vector.flatten() for vector in feature_vectors]\n",
    "\n",
    "# Check if the lengths of feature_vectors and labels are the same\n",
    "if len(dataframe_vectors) == len(labels):\n",
    "    # Create a pandas DataFrame with the feature vectors and labels\n",
    "    data = pd.DataFrame({'Label': labels, 'Feature Vector': dataframe_vectors})\n",
    "\n",
    "    # Save the DataFrame as a CSV file\n",
    "    data.to_csv('annotated_feature_vectors_12.csv', index=False)\n",
    "else:\n",
    "    print(\"Error: Length mismatch between feature vectors and labels.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
